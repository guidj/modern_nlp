{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernNLP: #6\n",
    "* Discussion around tokenization-free embeddings based on [CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation](https://arxiv.org/abs/2103.06874) from Clark, et al.\n",
    "* Notebook implements a version of the model prescribed in the paper\n",
    "\n",
    "```\n",
    "Authored by Guilherme Dinis Junior (PhD Candidate)\n",
    "H1 2021\n",
    "Stockholm University, Sweden\n",
    "```\n",
    "\n",
    "\n",
    "As dependencies, you need:\n",
    "    - Tensorflow (tested with 2.4.1)\n",
    "    - Pandas\n",
    "    - Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gZFBUQpxMStk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:31:53.942359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "import pathlib\n",
    "import os.path\n",
    "import ast\n",
    "import pandas as pd\n",
    "from IPython.core import display\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtCp_Q1gORp0",
    "outputId": "96554517-cd86-418c-bbc6-52889c2e5a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "O_fHEIcfOV4x",
    "outputId": "670e25e9-8f99-4219-ebb2-451bbbab1d94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4zEJS9yMMbye"
   },
   "outputs": [],
   "source": [
    "BASE_DATA_URL = \"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/\"\n",
    "FILES = [\"tsd_train\", \"tsd_test\", \"tsd_trial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6E-CCGWSMd77"
   },
   "outputs": [],
   "source": [
    "def download_data(base_url, files, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for filename in files:\n",
    "        uri = os.path.join(base_url, f\"{filename}.csv\")\n",
    "        output = os.path.join(output_dir, f\"{filename}.csv\")\n",
    "        if not os.path.exists(output):\n",
    "            request.urlretrieve(uri, filename=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wAHbHW2EMfGF"
   },
   "outputs": [],
   "source": [
    "def load_data(path, files):\n",
    "    data_frames = {}\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(os.path.join(path, f\"{filename}.csv\"))\n",
    "        df[\"spans\"] = df.spans.apply(ast.literal_eval)\n",
    "        data_frames[filename] = df\n",
    "    return data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UkKajmdAMgk-"
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(pathlib.Path.home(), \"fs\", \"toxic_spans\", \"raw\")\n",
    "download_data(BASE_DATA_URL, FILES, data_dir)\n",
    "dfs = load_data(data_dir, FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "8NLmX8GAM1TG",
    "outputId": "c8e52823-73c8-457e-facb-2498a7072c95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"tsd_trial\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"tsd_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mQJwJnyt5v9t"
   },
   "outputs": [],
   "source": [
    "max_text_len = max([dfs[key].text.apply(lambda x: len(x)).max() for key in FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItYIe9gD6CiC",
    "outputId": "5ecb5f38-b820-462e-8b15-6d48818dc457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5GUnZ2Xk6F2a",
    "outputId": "95167bb7-c98d-4b22-a2b2-7cd1f1f34f7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs[\"tsd_trial\"].text.apply(lambda x: len(x)).plot.hist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_text_len = min([dfs[key].text.apply(lambda x: len(x)).min() for key in FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oaKSTrOY6dne"
   },
   "outputs": [],
   "source": [
    "example_one_spans, example_one_text = dfs[\"tsd_trial\"].spans[0], dfs[\"tsd_trial\"].text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ykYpRfveM61c"
   },
   "outputs": [],
   "source": [
    "def highlight_text(spans, text):\n",
    "    spans_set = set(spans)\n",
    "    string = []\n",
    "    for i in range(len(text)):\n",
    "        if i in spans_set:\n",
    "            string.append(f\"<span style=\\\"color:#FF0000;\\\">{text[i]}</span>\")\n",
    "        else:\n",
    "            string.append(text[i])\n",
    "    paragraph = \"\".join(string)\n",
    "    return display.display(display.HTML(f\"<p>{paragraph}</p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "eawuglId8o_R",
    "outputId": "01cfef10-752e-4f5c-9e4b-3f0d9acd0f0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Because he's a <span style=\"color:#FF0000;\">m</span><span style=\"color:#FF0000;\">o</span><span style=\"color:#FF0000;\">r</span><span style=\"color:#FF0000;\">o</span><span style=\"color:#FF0000;\">n</span> and a <span style=\"color:#FF0000;\">b</span><span style=\"color:#FF0000;\">i</span><span style=\"color:#FF0000;\">g</span><span style=\"color:#FF0000;\">o</span><span style=\"color:#FF0000;\">t</span>. It's not any more complicated than that.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlight_text(example_one_spans, example_one_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGo0AEM69DAK"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HD8TnadZ9jq4"
   },
   "outputs": [],
   "source": [
    "MLM_MASK_RATE = 0.15\n",
    "MASK_UNICODE = ord('\\x00')\n",
    "PAD_UNICODE = ord('\\x01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wllwl75v-EgZ"
   },
   "outputs": [],
   "source": [
    "def encode_text_as_unicode(text):\n",
    "    return [ord(char) for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LfEf0T-19tUK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_data_as_unicode(dataframe: pd.DataFrame):\n",
    "    inputs = dataframe.text.apply(encode_text_as_unicode).values.tolist()\n",
    "    spans = dataframe.spans.values.tolist()\n",
    "    return inputs, spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bd1hEg2cAbg0"
   },
   "outputs": [],
   "source": [
    "data = {key: encode_data_as_unicode(dataframe) for key, dataframe in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fg8tFwG2Arm-"
   },
   "outputs": [],
   "source": [
    "def unicode_vocabulary(data):\n",
    "    # mask char will be unicode 0\n",
    "    codes = set([MASK_UNICODE, PAD_UNICODE])\n",
    "    for _, (inputs, _) in data.items():\n",
    "        for text_code in inputs:\n",
    "            codes.update(text_code)\n",
    "    return {code: index for index, code in enumerate(codes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gnlSrZnhBRhh"
   },
   "outputs": [],
   "source": [
    "vocabulary = unicode_vocabulary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iifn63CIBW8A",
    "outputId": "7e3a0399-1afc-4b82-9442-7d701c861a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "E5hQv2IqE1HK"
   },
   "outputs": [],
   "source": [
    "def create_masked_language_task_example(text_unicode, mask_rate: float, mask_unicode: int):\n",
    "    size = len(text_unicode)\n",
    "    max_chars = int(size * mask_rate)\n",
    "    # at least one char\n",
    "    start_index = random.randint(0, size - 1)\n",
    "    end_index = min(start_index + max_chars, size)\n",
    "    example = text_unicode[0:start_index] + [mask_unicode]*(end_index - start_index) + text_unicode[end_index:]\n",
    "    target = text_unicode[start_index:end_index]\n",
    "    return example, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oP3iutxtNVJi"
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, max_text_len: int, pad_code: int):\n",
    "    padding = max_text_len - len(sequence)\n",
    "    return np.concatenate([sequence, [pad_code]*padding]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9e_OGo-z9G_u"
   },
   "outputs": [],
   "source": [
    "def generate_masked_language_task_data(inputs, max_text_len: int, mask_rate: float, mask_unicode: int, pad_code: int, vocabulary):\n",
    "    # choose a starting point\n",
    "    # select at most 15% of contiguous characters to ommit\n",
    "    examples_and_targets = [create_masked_language_task_example(input_, mask_rate, mask_unicode) for input_ in inputs]\n",
    "    padded_data = []\n",
    "    for example, target in examples_and_targets:\n",
    "        # can be empty\n",
    "        if target:\n",
    "            try:\n",
    "                padded_masked_example = pad_sequence(example, max_text_len, pad_code)\n",
    "                padded_target = pad_sequence(target, int(max_text_len * mask_rate), pad_code)\n",
    "                true_example = masked_example_to_text_unicode(padded_masked_example, padded_target)\n",
    "                padded_true_example = pad_sequence(true_example, max_text_len, PAD_UNICODE)\n",
    "                # convert uni code to class ID\n",
    "                padded_true_example = [vocabulary[code] for code in padded_true_example]\n",
    "                yield padded_masked_example, padded_target, padded_true_example\n",
    "            except Exception:\n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qbAOqb3TRm_V"
   },
   "outputs": [],
   "source": [
    "def create_masked_language_task_dataset(inputs, max_text_len: int, vocabulary, mask_rate: float = MLM_MASK_RATE, mask_unicode: int = MASK_UNICODE, pad_code: int = PAD_UNICODE):\n",
    "    generator = generate_masked_language_task_data(inputs, max_text_len, mask_rate, mask_unicode, pad_code, vocabulary)\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32)))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dweG_mHYRl__"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:31:55.843276: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-07 21:31:55.843918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-07 21:31:55.868975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.869403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2070 computeCapability: 7.5\n",
      "coreClock: 1.725GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-07-07 21:31:55.869450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.869730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA GeForce GT 710 computeCapability: 3.5\n",
      "coreClock: 0.954GHz coreCount: 1 deviceMemorySize: 981.38MiB deviceMemoryBandwidth: 13.41GiB/s\n",
      "2021-07-07 21:31:55.869747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-07 21:31:55.871752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-07 21:31:55.871786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-07 21:31:55.873000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-07 21:31:55.873221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-07 21:31:55.874598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-07 21:31:55.875099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-07 21:31:55.875219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-07 21:31:55.875294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.875744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.876055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.876476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.876747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1847] Ignoring visible gpu device (device: 1, name: NVIDIA GeForce GT 710, pci bus id: 0000:03:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2021-07-07 21:31:55.876755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-07 21:31:55.877679: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-07 21:31:55.877870: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-07 21:31:55.877943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.878353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2070 computeCapability: 7.5\n",
      "coreClock: 1.725GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-07-07 21:31:55.878374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-07 21:31:55.878389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-07 21:31:55.878401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-07 21:31:55.878413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-07 21:31:55.878425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-07 21:31:55.878437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-07 21:31:55.878449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-07 21:31:55.878461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-07 21:31:55.878510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.878933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:55.879318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-07 21:31:55.879343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-07 21:31:56.270982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-07 21:31:56.271001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-07 21:31:56.271006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-07 21:31:56.271142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:56.271532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:56.271887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-07 21:31:56.272223: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-07-07 21:31:56.272244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6332 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "datasets = {key: create_masked_language_task_dataset(inputs, max_text_len, vocabulary) for key, (inputs, _) in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "p0iPoTPnR0ug"
   },
   "outputs": [],
   "source": [
    "def masked_example_to_text_unicode(example, target, pad_code: int = PAD_UNICODE):\n",
    "    example = np.array(example)\n",
    "    target = np.array(target)\n",
    "    example = example[0:np.where(example == pad_code)[0][0]]\n",
    "    target = target[0:np.where(target == pad_code)[0][0]]\n",
    "    where_masked = np.where(example == 0)\n",
    "    start_index = where_masked[0][0]\n",
    "    end_index = where_masked[0][-1]\n",
    "    return np.concatenate([example[0:start_index], target, example[end_index+1:]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SdVNfdf9VKx9"
   },
   "outputs": [],
   "source": [
    "def unicode_to_text(text_unicode):\n",
    "    return \"\".join([chr(code) for code in text_unicode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6Y-MecXVI3d",
    "outputId": "4ba5fc0b-797f-420d-e408-a84eaa9e3128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because he's a moron and a bigot. It's not any more complicated than that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:31:56.348274: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-07 21:31:56.348582: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    }
   ],
   "source": [
    "for example, target, true in datasets[\"tsd_trial\"].take(1):\n",
    "    print(unicode_to_text(masked_example_to_text_unicode(example, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmG3pxJNVxV3"
   },
   "source": [
    "## Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pn3I-Fancb93"
   },
   "outputs": [],
   "source": [
    "NUM_BUCKETS = 16000\n",
    "DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "5PHqffMFbouq"
   },
   "outputs": [],
   "source": [
    "def create_hash_fn(max_int: int):\n",
    "    a = np.random.randint(1, max_int)\n",
    "    b = np.random.randint(1, max_int)\n",
    "    if a % 2 == 0:\n",
    "        a += 1\n",
    "    def fn(x):\n",
    "        return (a * x + b) & ((1 << 32) - 1)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dOdOp85Ff4KL"
   },
   "outputs": [],
   "source": [
    "def hash_text_unicode(hash_fn, text_unicode, num_buckets):\n",
    "    return tf.map_fn(lambda x: hash_fn(x) % num_buckets, text_unicode, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Uiw27zi6g-8t"
   },
   "outputs": [],
   "source": [
    "def batch_hash_text_unicode(hash_fn, batch_text_unicode, num_buckets):\n",
    "    return tf.map_fn(lambda x: hash_text_unicode(hash_fn, x, num_buckets), batch_text_unicode, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKRbVIW9gAh2",
    "outputId": "483d7dce-dabb-4d1d-ea38-00aaeba07f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1000), dtype=int32, numpy=\n",
       "array([[14323, 15118, 13244, 11370, 14110, 12236, 15118, 14465,  1929,\n",
       "        15118,  5024, 12236, 14465, 11370, 14465,  6614,  8488,   481,\n",
       "          481,   481,   481,   481,   481,   481,   481,   481,   481,\n",
       "          481,  2866,   992,  8488, 13173, 11583, 14465,  4882, 13173,\n",
       "         5024, 12236, 14465,  7551,  8488, 13173, 14465, 11370,  7551,\n",
       "         1858, 14465,  6614,  8488, 11299, 15118, 14465, 13244,  8488,\n",
       "         6614,  9425,  5677,  2866, 13244, 11370, 13173, 15118, 14181,\n",
       "        14465, 13173,  1929, 11370,  7551, 14465, 13173,  1929, 11370,\n",
       "        13173, 11583,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,  1418,\n",
       "         1418]], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hash_text_unicode(create_hash_fn(1232), tf.expand_dims(example, 0), NUM_BUCKETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "3y1a8fiEVvPW"
   },
   "outputs": [],
   "source": [
    "class HashingProjection(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_funcs: int, num_buckets: int, dim: int):\n",
    "        super().__init__()\n",
    "        if dim % num_funcs != 0:\n",
    "            raise ValueError(f\"Dimension is not divisible by number of functions: {dim} and {num_funcs}\")        \n",
    "\n",
    "        self.num_funcs = num_funcs\n",
    "        self.num_buckets = num_buckets\n",
    "        self.hash_functions = [create_hash_fn(2 ** 18) for _ in range(self.num_funcs)]\n",
    "        self.embeddings = [\n",
    "            tf.keras.layers.Embedding(input_dim=num_buckets, output_dim=int(dim / num_funcs)) for _ in range(self.num_funcs)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (B x T)\n",
    "        # hash inputs, lookup embeddings K times\n",
    "        inputs_ = [batch_hash_text_unicode(hash_fn, inputs, self.num_buckets) for hash_fn in self.hash_functions]\n",
    "        # concatenate K embeddings\n",
    "        embeddings_ = tf.concat([emb(hash_keys) for hash_keys, emb in zip(inputs_, self.embeddings)], axis=-1)\n",
    "        # outputs: (B x T x dim)\n",
    "        return embeddings_\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_funcs\": self.num_funcs, \n",
    "                       \"num_buckets\": self.num_buckets,\n",
    "                       \"dim\": self.dim})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "glkCDcRojlML"
   },
   "outputs": [],
   "source": [
    "hashing_projection = HashingProjection(num_funcs=8, num_buckets=NUM_BUCKETS, dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXEgCclKjZ5H",
    "outputId": "c4b37d63-9211-4ba8-d830-d0eb0c5a1be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 768)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    print(hashing_projection(example).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgBBednCvXhC"
   },
   "source": [
    "## Local Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vBnrWDZ-6DmQ"
   },
   "outputs": [],
   "source": [
    "LOCAL_TFX_WINDOW_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "d0uSWF9m0xHN"
   },
   "outputs": [],
   "source": [
    "def expand_mask(mask: tf.Tensor, batch_size: int, seq_len: int):\n",
    "    expanded = tf.expand_dims(mask, 0)\n",
    "    mask_exp = tf.matmul(tf.transpose(expanded), expanded)\n",
    "    tiled = tf.tile(mask_exp, multiples=[batch_size, 1])\n",
    "    return tf.reshape(tiled, shape=(batch_size, seq_len, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "EHg60olPvaax"
   },
   "outputs": [],
   "source": [
    "class LocalTransformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, window_size: int, key_dim: int, seq_len: int):\n",
    "        super().__init__()\n",
    "        if seq_len % window_size != 0:\n",
    "            raise ValueError(f\"Sequence length is not divisible by window size: {seq_len} and {window_size}\")\n",
    "        self.seq_len = seq_len           \n",
    "        self.window_size = window_size\n",
    "        self.num_heads = int(seq_len / window_size)\n",
    "        self.attentions = [\n",
    "            tf.keras.layers.MultiHeadAttention(num_heads=1, key_dim=key_dim) for _ in range(self.num_heads)\n",
    "        ]\n",
    "        self._masks = []\n",
    "        for start_index in range(0, self.seq_len, self.window_size):\n",
    "            end_index = start_index + self.window_size\n",
    "            end_mask = tf.where(tf.range(self.seq_len) < end_index, True, False)\n",
    "            start_mask = tf.where(tf.range(self.seq_len) >= start_index, True, False)\n",
    "            mask = tf.cast(tf.math.logical_and(end_mask, start_mask), tf.int32)\n",
    "            self._masks.append(mask)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # inputs: (B x T x key_dim)\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        # compute masks ([B x T x key_dim])\n",
    "        masks = [expand_mask(mask, batch_size, seq_len) for mask in self._masks]\n",
    "        # compute local attention\n",
    "        # attention (B x T x key_dim), weights (B x T x T)\n",
    "        outputs = [\n",
    "            attx(query=inputs, value=inputs, attention_mask=mask, return_attention_scores=True) \n",
    "            for attx, mask in zip(self.attentions, masks)\n",
    "        ]\n",
    "        # slice and gather\n",
    "        attx_outputs = []\n",
    "        attx_scores = []\n",
    "        for start_index, output in zip(range(0, self.seq_len, self.window_size), outputs):\n",
    "            end_index = start_index + self.window_size\n",
    "            attx_output, attx_score = output\n",
    "            attx_output_slice = attx_output[:, start_index:end_index, :]\n",
    "            # second dim for scores is the head\n",
    "            attx_score_slice = tf.squeeze(attx_score, 1)[:, start_index:end_index, :]\n",
    "            attx_outputs.append(attx_output_slice)\n",
    "            attx_scores.append(attx_score_slice)\n",
    "        \n",
    "        composed_attx_output = tf.concat(attx_outputs, axis=1)\n",
    "        composed_attx_scores = tf.concat(attx_scores, axis=1)\n",
    "        return composed_attx_output, composed_attx_scores\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"window_size\": self.window_size, \n",
    "                       \"key_dim\": self.key_dim,\n",
    "                       \"seq_len\": self.seq_len})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5pdefm4q9sq8"
   },
   "outputs": [],
   "source": [
    "local_transformer_x0 = LocalTransformer(window_size=LOCAL_TFX_WINDOW_SIZE, key_dim=DIM, seq_len=max_text_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGeHwQBk9t9A",
    "outputId": "d9c79b1f-ccdf-44b9-80d8-8184742a8d2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:32:16.239423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2, 1000, 768), dtype=float32, numpy=\n",
      "array([[[ 6.1520922e-04, -2.2145612e-04, -2.6955013e-04, ...,\n",
      "         -6.2685169e-05, -2.4571121e-04, -1.6172578e-04],\n",
      "        [ 6.1520922e-04, -2.2145445e-04, -2.6954728e-04, ...,\n",
      "         -6.2686653e-05, -2.4571107e-04, -1.6172473e-04],\n",
      "        [ 6.1520888e-04, -2.2145588e-04, -2.6954833e-04, ...,\n",
      "         -6.2685926e-05, -2.4571031e-04, -1.6172559e-04],\n",
      "        ...,\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03],\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03],\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03]],\n",
      "\n",
      "       [[-3.4226646e-04, -6.5104148e-05,  6.2268588e-04, ...,\n",
      "         -3.5325054e-04,  1.6773960e-05, -6.7074943e-05],\n",
      "        [-3.4226506e-04, -6.5105356e-05,  6.2268606e-04, ...,\n",
      "         -3.5324768e-04,  1.6771079e-05, -6.7075729e-05],\n",
      "        [-3.4226535e-04, -6.5104367e-05,  6.2268745e-04, ...,\n",
      "         -3.5324847e-04,  1.6772961e-05, -6.7074623e-05],\n",
      "        ...,\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03],\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03],\n",
      "        [ 2.1474310e-03, -6.5939786e-04,  1.0151086e-04, ...,\n",
      "         -1.1019165e-03, -8.7780622e-04,  2.7069363e-03]]], dtype=float32)>, <tf.Tensor: shape=(2, 1000, 1000), dtype=float32, numpy=\n",
      "array([[[0.00499999, 0.005     , 0.00499999, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.00500002, 0.00500001, 0.00500001, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.00500001, 0.00499999, 0.005     , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ]],\n",
      "\n",
      "       [[0.00499999, 0.00499999, 0.00500001, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.005     , 0.00499999, 0.00499998, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.00499998, 0.00499998, 0.00500001, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.005     ,\n",
      "         0.005     , 0.005     ]]], dtype=float32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:32:16.541449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    print(local_transformer_x0(hashing_projection(example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcFMXdIMJg_v"
   },
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OigwAzYhLjWi"
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLE_DIM = int(DIM / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ECtbhuV2JlVD"
   },
   "outputs": [],
   "source": [
    "class Downsampling(tf.keras.layers.Layer):\n",
    "    def __init__(self, key_dim: int, strides: int):\n",
    "        super().__init__()\n",
    "        # It's unclear if activation was used in the paper\n",
    "        self.conv = tf.keras.layers.Conv1D(filters=key_dim, kernel_size=1, strides=strides)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (B x T x key_dim)\n",
    "        return self.conv(inputs)\n",
    "        \n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_BqJ8cujLGBq"
   },
   "outputs": [],
   "source": [
    "downsample = Downsampling(key_dim=DIM, strides=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFT-0bnuJuXf",
    "outputId": "b40cffe8-709a-4285-bbaf-c02287041fef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 21:32:25.658865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 5.10374608e-04  1.00427089e-04  9.48430461e-05 ... -8.26528703e-04\n",
      "    6.43811189e-04 -1.59135775e-03]\n",
      "  [ 5.10376878e-04  1.00428086e-04  9.48419838e-05 ... -8.26529867e-04\n",
      "    6.43812411e-04 -1.59135996e-03]\n",
      "  [ 5.10375889e-04  1.00427489e-04  9.48427332e-05 ... -8.26528994e-04\n",
      "    6.43811596e-04 -1.59135822e-03]\n",
      "  ...\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]]\n",
      "\n",
      " [[ 4.67280828e-04  2.04043681e-04 -1.42556569e-03 ... -1.44201797e-03\n",
      "    5.02276234e-04 -7.38587230e-04]\n",
      "  [ 4.67281847e-04  2.04044467e-04 -1.42556441e-03 ... -1.44201447e-03\n",
      "    5.02274197e-04 -7.38585601e-04]\n",
      "  [ 4.67281759e-04  2.04045355e-04 -1.42556755e-03 ... -1.44201808e-03\n",
      "    5.02275303e-04 -7.38588511e-04]\n",
      "  ...\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]\n",
      "  [-1.95375551e-03  6.80103491e-04  2.64765229e-04 ...  4.89813683e-04\n",
      "    4.77149151e-04 -1.94386055e-03]]], shape=(2, 250, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    outputs, _ = local_transformer_x0(hashing_projection(example))\n",
    "    print(downsample(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Te3ZE5gMEin"
   },
   "source": [
    "## Transformer Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m2yINZSVDoQ"
   },
   "source": [
    "Adapted from: https://www.tensorflow.org/text/tutorials/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "lwQfQXnjVbju"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wTTOU6QhVdLC"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "zbVYduiHWVna"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "8Tu7SjxDWBbp"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(value=x, key=x, query=x, attention_mask=mask, \n",
    "                                  return_attention_scores=True)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2, attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "NzahddK5WEo5"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"Note: This layer isn't used by the transformer\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(value=x, key=x, query=x,\n",
    "                                               attention_mask=look_ahead_mask, \n",
    "                                               return_attention_scores=True)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            value=enc_output, key=enc_output, query=out1, attention_mask=padding_mask,\n",
    "            return_attention_scores=True)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Trl7_GdLVCn8"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        attn = None\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x, attn  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "2RwQU1R7U9ex"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"Note: this layer isn't used by the transformer\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        # x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "prDvodYdUGap"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        \"\"\"\n",
    "        Note: vocabulary isn't used here since\n",
    "        1. Our inputs are embeddings instead of tokens\n",
    "        2. This transformer has no classifier head attached\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, rate)\n",
    "        \n",
    "        # Transformer only have an encoder\n",
    "        # self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "        #                       target_vocab_size, pe_target, rate)\n",
    "        # self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output, attention_weights = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "        return enc_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wc1V0m6mVwER",
    "outputId": "169fe729-ff40-408f-ec98-b783b8ddbdde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 38, 512]), TensorShape([64, 38, 512]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38, 512), dtype=tf.float32, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36, 512), dtype=tf.float32, minval=0, maxval=200)\n",
    "\n",
    "fn_out, attention_weights = sample_transformer(temp_input, temp_target, training=False, enc_padding_mask=None, look_ahead_mask=None, dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape, attention_weights.shape  # (batch_size, tar_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Czp0WDeHcHM7"
   },
   "source": [
    "## Deep Transformer Stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "tIK7sAc0cHom"
   },
   "outputs": [],
   "source": [
    "class DeepTransformerStack(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size: int, output_vocab_size: int,\n",
    "                 num_layers: int, num_heads: int, key_dim: int, \n",
    "                 dff: int, max_input_seq: int, max_target_seq: int):\n",
    "        super().__init__()\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.dff = dff\n",
    "        self.max_input_seq = max_input_seq\n",
    "        self.max_target_seq = max_target_seq\n",
    "        # It's unclear if activation was used in the paper\n",
    "        self.transformer = Transformer(\n",
    "            num_layers=num_layers, d_model=key_dim, num_heads=num_heads, \n",
    "            dff=dff, input_vocab_size=input_vocab_size, \n",
    "            target_vocab_size=output_vocab_size,\n",
    "            pe_input=max_input_seq, pe_target=max_target_seq\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, inputs, targets, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        # inputs: (B x T' x key_dim)\n",
    "        return self.transformer(inp=inputs, \n",
    "                                tar=targets, \n",
    "                                training=training, \n",
    "                                enc_padding_mask=enc_padding_mask, \n",
    "                                look_ahead_mask=look_ahead_mask, \n",
    "                                dec_padding_mask=dec_padding_mask)\n",
    "        \n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_vocab_size\": self.input_vocab_size,\n",
    "            \"output_vocab_size\": self.output_vocab_size,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dff\": self.dff,\n",
    "            \"max_input_seq\": self.max_input_seq,\n",
    "            \"max_target_seq\": self.max_target_seq,\n",
    "        })\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "pTmCT9-VoGqO"
   },
   "outputs": [],
   "source": [
    "deep_transformer = DeepTransformerStack(\n",
    "    input_vocab_size=len(vocabulary), \n",
    "    output_vocab_size=len(vocabulary),\n",
    "    num_layers=2, \n",
    "    num_heads=2,\n",
    "    key_dim=DIM,\n",
    "    dff=DIM,\n",
    "    max_input_seq=max_text_len, \n",
    "    max_target_seq=max_text_len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sq2R6Wo6oKGD",
    "outputId": "a046b4cc-e517-48ba-d561-52a4758c1446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 250, 768)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    outputs, _ = local_transformer_x0(hashing_projection(example))\n",
    "    outputs = downsample(outputs)\n",
    "    # dtf_inputs, dtf_targets = outputs[:, 0:-1, :], outputs[:, 1:, :]\n",
    "    # unclear what the decoder input is (or if it's used)\n",
    "    dtf_inputs, dtf_targets = outputs, outputs\n",
    "    outputs, _ = deep_transformer(dtf_inputs, dtf_targets,\n",
    "                                  enc_padding_mask=None,\n",
    "                                  look_ahead_mask=None,\n",
    "                                  dec_padding_mask=None)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpZJq3_uopcv"
   },
   "source": [
    "## Upsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ahp_AxJtooTH"
   },
   "outputs": [],
   "source": [
    "class Upsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, multiplier: int, key_dim: int):\n",
    "        super().__init__()\n",
    "        self.multiplier = multiplier\n",
    "        self.key_dim = key_dim\n",
    "        self.conv = tf.keras.layers.Conv1D(filters=key_dim, kernel_size=1, strides=1)\n",
    "\n",
    "    def call(self, inputs, h_init):\n",
    "        # inputs: (B x T' x key_dim)\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        tiled = tf.tile(inputs, multiples=[1, self.multiplier, 1])\n",
    "        reshaped = tf.reshape(tiled, (batch_size, seq_len * self.multiplier, -1))\n",
    "        upsampled = tf.concat([h_init, reshaped], axis=-1)\n",
    "        return self.conv(upsampled)\n",
    "        \n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"multiplier\": self.multiplier,\n",
    "                       \"key_dim\": self.key_dim})\n",
    "        return config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "MHdMSEEz03Y1"
   },
   "outputs": [],
   "source": [
    "upsample = Upsample(multiplier = 4, key_dim = DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwZu8FUT05uT",
    "outputId": "6b1cf859-60c7-402c-8a75-002221dd813f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 768)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    hinit, _ = local_transformer_x0(hashing_projection(example))\n",
    "    outputs = downsample(hinit)\n",
    "    # dtf_inputs, dtf_targets = outputs[:, 0:-1, :], outputs[:, 1:, :]\n",
    "    # unclear what the decoder input is (or if it's used)\n",
    "    dtf_inputs, dtf_targets = outputs, outputs\n",
    "    outputs, _ = deep_transformer(dtf_inputs, dtf_targets,\n",
    "                                  enc_padding_mask=None,\n",
    "                                  look_ahead_mask=None,\n",
    "                                  dec_padding_mask=None)\n",
    "                                  \n",
    "    outputs = upsample(outputs, hinit)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0j_6_FD1wKw"
   },
   "source": [
    "## Final Projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eGf_OjuJ06e_"
   },
   "outputs": [],
   "source": [
    "final_transformer = DeepTransformerStack(\n",
    "    input_vocab_size=len(vocabulary), \n",
    "    output_vocab_size=len(vocabulary),\n",
    "    num_layers=1, \n",
    "    num_heads=1,\n",
    "    key_dim=DIM,\n",
    "    dff=DIM,\n",
    "    max_input_seq=max_text_len, \n",
    "    max_target_seq=max_text_len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHXh3QLc1ye9",
    "outputId": "ee4b489a-f1d9-4012-cc55-458d3a3d9d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 768)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    hinit, _ = local_transformer_x0(hashing_projection(example))\n",
    "    outputs = downsample(hinit)\n",
    "    # dtf_inputs, dtf_targets = outputs[:, 0:-1, :], outputs[:, 1:, :]\n",
    "    # unclear what the decoder input is (or if it's used)\n",
    "    dtf_inputs, dtf_targets = outputs, outputs\n",
    "    outputs, _ = deep_transformer(dtf_inputs, dtf_targets,\n",
    "                                  enc_padding_mask=None,\n",
    "                                  look_ahead_mask=None,\n",
    "                                  dec_padding_mask=None)\n",
    "                                  \n",
    "    outputs = upsample(outputs, hinit)\n",
    "    outputs, _ = final_transformer(outputs, outputs,\n",
    "                                enc_padding_mask=None,\n",
    "                                look_ahead_mask=None,\n",
    "                                dec_padding_mask=None)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ddTZGcg_2BtS"
   },
   "outputs": [],
   "source": [
    "class CANINE(tf.keras.Model):\n",
    "    def __init__(self, hashing_projection, local_transformer, downsample, deep_transformer, upsample, final_transformer, vocabulary):\n",
    "        super().__init__()\n",
    "        self.hashing_projection = hashing_projection\n",
    "        self.local_transformer = local_transformer\n",
    "        self.downsample = downsample\n",
    "        self.deep_transformer = deep_transformer\n",
    "        self.upsample = upsample\n",
    "        self.final_transformer = final_transformer\n",
    "\n",
    "        self.classify = tf.keras.layers.Dense(units=len(vocabulary), activation=\"relu\")\n",
    "\n",
    "    def call(self, inputs, enc_padding_mask = None, look_ahead_mask = None, dec_padding_mask = None):\n",
    "        # inputs: (B x T x key_dim)\n",
    "        hashing_projection = self.hashing_projection(inputs)\n",
    "        hinit, _ = self.local_transformer(hashing_projection)\n",
    "        outputs = self.downsample(hinit)\n",
    "        # dtf_inputs, dtf_targets = outputs[:, 0:-1, :], outputs[:, 1:, :]\n",
    "        # unclear what the decoder input is (or if it's used)\n",
    "        dtf_inputs, dtf_targets = outputs, outputs\n",
    "        outputs, _ = self.deep_transformer(dtf_inputs, dtf_targets,\n",
    "                                           enc_padding_mask=enc_padding_mask,\n",
    "                                           look_ahead_mask=look_ahead_mask,\n",
    "                                           dec_padding_mask=dec_padding_mask)\n",
    "                                    \n",
    "        outputs = upsample(outputs, hinit)\n",
    "        outputs, weights = final_transformer(outputs, outputs,\n",
    "                                       enc_padding_mask=enc_padding_mask,\n",
    "                                       look_ahead_mask=look_ahead_mask,\n",
    "                                       dec_padding_mask=dec_padding_mask)\n",
    "        return outputs, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "hUsIawli3k8O"
   },
   "outputs": [],
   "source": [
    "canine = CANINE(hashing_projection=hashing_projection, local_transformer=local_transformer_x0,\n",
    "                downsample=downsample, deep_transformer=deep_transformer, \n",
    "                upsample=upsample, final_transformer=final_transformer,\n",
    "                vocabulary=vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5B7rGVO3l4X",
    "outputId": "9845bdf6-2a21-4b00-ed1e-a80fdd9db47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 768)\n"
     ]
    }
   ],
   "source": [
    "for example, target, _ in datasets[\"tsd_trial\"].batch(2).take(1):    \n",
    "    outputs, _ = canine(example)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0uT7G5m4Dyi"
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TBLVWmbj33vM"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "1PECLbjc36-9"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "WS0sZsva4Cwp"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "n5bnthJt5UdZ"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "FE2m72-K5YMl"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "AacbYweT4rFq"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "NkpjeUcW4WvI"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar = tf.cast(tar, tf.int64)\n",
    "    # tar_inp = tar[:, :-1]\n",
    "    # tar_real = tar[:, 1:]\n",
    "\n",
    "    # enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    # print(enc_padding_mask.shape, combined_mask.shape, dec_padding_mask.shape)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # print(inp.shape, tar.shape)\n",
    "        predictions, _ = canine(inp,\n",
    "                                enc_padding_mask=None,\n",
    "                                look_ahead_mask=None,\n",
    "                                dec_padding_mask=None)\n",
    "        logits = canine.classify(predictions)\n",
    "        # print(predictions.shape)\n",
    "        # reconstruct original example\n",
    "        loss = loss_function(tar, logits)\n",
    "\n",
    "    gradients = tape.gradient(loss, canine.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, canine.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./job_dir\"\n",
    "ckpt = tf.train.Checkpoint(canine=canine,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jVy0tQ1d4vno",
    "outputId": "5fb986e8-b368-41fb-c7a2-e06d7fd6420e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/guilherme/.pyenv/versions/3.7.5/envs/nlp/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Epoch 1 Batch 0 Loss 5.7964 Accuracy 0.0008\n",
      "Epoch 1 Batch 100 Loss 5.0341 Accuracy 0.0212\n",
      "Epoch 1 Batch 200 Loss 4.8786 Accuracy 0.0514\n",
      "Epoch 1 Batch 300 Loss 4.0617 Accuracy 0.2094\n",
      "Epoch 1 Batch 400 Loss 3.6258 Accuracy 0.2931\n",
      "Epoch 1 Batch 500 Loss 3.1966 Accuracy 0.3800\n",
      "Epoch 1 Batch 600 Loss 3.0118 Accuracy 0.4163\n",
      "Epoch 1 Batch 700 Loss 2.8716 Accuracy 0.4436\n",
      "Epoch 1 Batch 800 Loss 2.7753 Accuracy 0.4625\n",
      "Epoch 1 Batch 900 Loss 2.6986 Accuracy 0.4776\n",
      "Epoch 1 Loss 2.6392 Accuracy 0.4894\n",
      "Time taken for 1 epoch: 6500.13 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.6067 Accuracy 0.5170\n",
      "Epoch 2 Batch 100 Loss 2.0123 Accuracy 0.6112\n",
      "Epoch 2 Batch 200 Loss 2.0397 Accuracy 0.6060\n",
      "Epoch 2 Batch 300 Loss 2.0400 Accuracy 0.6058\n",
      "Epoch 2 Batch 400 Loss 2.0444 Accuracy 0.6054\n",
      "Epoch 2 Batch 500 Loss 2.0340 Accuracy 0.6074\n",
      "Epoch 2 Batch 600 Loss 2.0428 Accuracy 0.6059\n",
      "Epoch 2 Batch 700 Loss 2.0408 Accuracy 0.6061\n",
      "Epoch 2 Batch 800 Loss 2.0481 Accuracy 0.6047\n",
      "Epoch 2 Batch 900 Loss 2.0521 Accuracy 0.6040\n",
      "Saving checkpoint for epoch 2 at ./job_dir/ckpt-1\n",
      "Epoch 2 Loss 2.0489 Accuracy 0.6048\n",
      "Time taken for 1 epoch: 6516.99 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.5983 Accuracy 0.5170\n",
      "Epoch 3 Batch 100 Loss 2.0115 Accuracy 0.6112\n",
      "Epoch 3 Batch 200 Loss 1.9981 Accuracy 0.6261\n",
      "Epoch 3 Batch 300 Loss 1.8617 Accuracy 0.6809\n",
      "Epoch 3 Batch 400 Loss 1.7658 Accuracy 0.7092\n",
      "Epoch 3 Batch 500 Loss 1.6926 Accuracy 0.7290\n",
      "Epoch 3 Batch 600 Loss 1.6640 Accuracy 0.7390\n",
      "Epoch 3 Batch 700 Loss 1.6324 Accuracy 0.7478\n",
      "Epoch 3 Batch 800 Loss 1.6194 Accuracy 0.7527\n",
      "Epoch 3 Batch 900 Loss 1.6082 Accuracy 0.7568\n",
      "Epoch 3 Loss 1.5917 Accuracy 0.7609\n",
      "Time taken for 1 epoch: 6514.10 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    start = time.time()\n",
    "    \n",
    "    # because we create the ds from a generator, it can only be iterated over once\n",
    "    # bar using Dataset.repeat, relingquishing control of epochs\n",
    "    datasets = {key: create_masked_language_task_dataset(inputs, max_text_len, vocabulary) for key, (inputs, _) in data.items()}\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    # Adjust batch size based on hardware\n",
    "    for (batch, (inp, _, tar)) in enumerate(datasets[\"tsd_train\"].batch(8)):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mun1YCIN7zr",
    "outputId": "bf6e94d9-537e-48ac-f289-db8121a15c4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CANINE at 0x7f10c3a65dd0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f57PDMk1N94n"
   },
   "source": [
    "Things to experiment with:\n",
    "  - Make softmax more efficient (focus only on targets to be predicted)\n",
    "  - Compare expansion > compression > expansion with simpler modules in the middle\n",
    "  - Train downstream tasks - e.g. toxic span\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "guilherme-canine-experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
